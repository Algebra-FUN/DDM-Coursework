{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def CVError(model,X,Y,cv=5):\n",
    "    return 1-cross_val_score(model,X,Y,cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Classification on 20newsgroup Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=pd.read_table(r'../data/20newsgroup/documents.txt',header=None)\n",
    "wordlist=pd.read_table(r'../data/20newsgroup/wordlist.txt',header=None)[0].tolist()\n",
    "target=pd.read_table(r'../data/20newsgroup/newsgroups.txt',header=None)[0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.zeros((16242,100),dtype=int)\n",
    "for index, row in doc.iterrows():\n",
    "    i,j = row[0],row[1]\n",
    "    data[i-1,j-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aids</th>\n",
       "      <th>baseball</th>\n",
       "      <th>bible</th>\n",
       "      <th>bmw</th>\n",
       "      <th>cancer</th>\n",
       "      <th>car</th>\n",
       "      <th>card</th>\n",
       "      <th>case</th>\n",
       "      <th>children</th>\n",
       "      <th>christian</th>\n",
       "      <th>...</th>\n",
       "      <th>university</th>\n",
       "      <th>version</th>\n",
       "      <th>video</th>\n",
       "      <th>vitamin</th>\n",
       "      <th>war</th>\n",
       "      <th>water</th>\n",
       "      <th>win</th>\n",
       "      <th>windows</th>\n",
       "      <th>won</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16242 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aids  baseball  bible  bmw  cancer  car  card  case  children  \\\n",
       "0         0         0      0    0       0    0     0     0         0   \n",
       "1         0         0      0    0       0    0     0     0         0   \n",
       "2         0         0      0    0       0    0     0     0         0   \n",
       "3         0         0      0    0       0    0     0     0         0   \n",
       "4         0         0      0    0       0    0     0     0         0   \n",
       "...     ...       ...    ...  ...     ...  ...   ...   ...       ...   \n",
       "16237     0         0      0    0       0    0     0     0         0   \n",
       "16238     0         0      0    0       0    0     0     0         0   \n",
       "16239     0         0      0    0       0    0     0     0         0   \n",
       "16240     0         0      0    0       0    0     0     0         0   \n",
       "16241     0         0      0    0       0    0     0     0         0   \n",
       "\n",
       "       christian  ...  university  version  video  vitamin  war  water  win  \\\n",
       "0              0  ...           0        0      1        0    0      0    0   \n",
       "1              0  ...           0        0      0        0    0      0    0   \n",
       "2              0  ...           0        1      0        0    0      0    0   \n",
       "3              0  ...           1        0      0        0    0      0    0   \n",
       "4              0  ...           0        1      0        0    0      0    0   \n",
       "...          ...  ...         ...      ...    ...      ...  ...    ...  ...   \n",
       "16237          0  ...           0        0      0        0    0      0    0   \n",
       "16238          0  ...           0        0      0        0    0      0    0   \n",
       "16239          1  ...           0        0      0        0    0      0    1   \n",
       "16240          0  ...           0        0      0        0    0      0    0   \n",
       "16241          1  ...           0        0      0        0    0      0    0   \n",
       "\n",
       "       windows  won  world  \n",
       "0            0    0      0  \n",
       "1            0    0      0  \n",
       "2            0    0      0  \n",
       "3            0    0      0  \n",
       "4            0    0      0  \n",
       "...        ...  ...    ...  \n",
       "16237        0    0      0  \n",
       "16238        0    0      0  \n",
       "16239        0    0      0  \n",
       "16240        0    0      1  \n",
       "16241        0    0      0  \n",
       "\n",
       "[16242 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf=pd.DataFrame(data,columns=wordlist)\n",
    "datadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Xtest,Y,Ytest=train_test_split(datadf,target,test_size=0.1,random_state=5054)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Build a random forest for this dataset \n",
    "and report the 5-fold cross validation value of the misclassification error. \n",
    "Note that you need to train the model by yourself, i.e., how many predictors \n",
    "are chosen in each tree and how many trees are used. There is no benchmark. Stop tuning when \n",
    "you feel appropriate. Report the best CV error, the corresponding confusion matrix and tuning \n",
    "parameters. What are the ten most important keywords based on variable importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 90, 'max_features': 2}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': np.arange(\n",
    "    20, 100, 10), 'max_features': np.arange(0, 10, 1)}\n",
    "RF = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                        param_distributions=parameters, cv=5)\n",
    "RF.fit(X, Y)\n",
    "print(RF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best CV error: 0.18717899877054156\n",
      "confusion matrix:\n",
      " [[416  32  50  24]\n",
      " [ 17 262  21  17]\n",
      " [ 20  13 148  24]\n",
      " [ 28  35  36 482]]\n",
      "tuning parameters: {'n_estimators': 90, 'max_features': 2}\n",
      "ten most important keywords:\n",
      " ['windows', 'car', 'christian', 'god', 'government', 'team', 'jews', 'religion', 'space', 'graphics']\n"
     ]
    }
   ],
   "source": [
    "RF_best = RF.best_estimator_\n",
    "RF_best.fit(X,Y)\n",
    "top10=[datadf.columns.values[i] for i in (np.argsort(RF_best.feature_importances_)[-1:-11:-1])]\n",
    "print(\"best CV error:\",CVError(RF_best,X,Y,cv=5)) \n",
    "print(\"confusion matrix:\\n\",confusion_matrix(RF_best.predict(Xtest),Ytest))\n",
    "print(\"tuning parameters:\",RF.best_params_)\n",
    "print(\"ten most important keywords:\\n\", top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a boosting tree for this dataset \n",
    "and report the 5-fold cross validation value of the \n",
    "misclassification error. Similarly, report the best CV error,  the corresponding confusion matrix and \n",
    "tuning parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "Y0 = Y-1\n",
    "Y0test = Ytest-1\n",
    "\n",
    "booster = GridSearchCV(\n",
    "    xgb.XGBClassifier(max_depth=5, booster='gbtree', objective='multi:softmax'),\n",
    "    param_grid={'n_estimators': np.arange(20, 100, 10), 'learning_rate': (0.1, 0.01)},\n",
    "    cv=5)\n",
    "booster.fit(X, Y0)\n",
    "print(booster.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best CV error: 0.18738370571995389\n",
      "confusion matrix:\n",
      " [[428  31  61  33]\n",
      " [  6 250   8   9]\n",
      " [ 21  15 145  32]\n",
      " [ 26  46  41 473]]\n",
      "tuning parameters: {'learning_rate': 0.1, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "booster_best=booster.best_estimator_\n",
    "print(\"best CV error:\",CVError(booster_best,X,Y0,cv=5)) \n",
    "print(\"confusion matrix:\\n\",confusion_matrix(booster_best.predict(Xtest),Y0test))\n",
    "print(\"tuning parameters:\",booster.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare the results from random forest and boosting trees. \n",
    "\n",
    "The result of the best CV error of random forest and boosting trees is quite similar. The parameter of n_estimators(the number of trees) is similar based on the limitation from 10 to 100. However, the boostring trees is more difficult to train, since you should tune the learning rate and max_depth by youself and it takes more time to train than random forest. Both of them consume much time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build a multi-class LDA classifier. \n",
    "Report the 5-fold CV error of misclassification and the confusion \n",
    "matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV error: 0.20058739755877364\n",
      "confusion matrix:\n",
      " [[416  35  55  34]\n",
      " [  3 238   9  13]\n",
      " [ 32  24 145  37]\n",
      " [ 30  45  46 463]]\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(X, Y)\n",
    "\n",
    "print(\"5-fold CV error:\",CVError(lda,X,Y,cv=5))\n",
    "print(\"confusion matrix:\\n\",confusion_matrix(lda.predict(Xtest),Ytest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a multi-class QDA classifier. \n",
    "Report the 5-fold CV error of misclassification and the confusion \n",
    "matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV error: 0.3147670276728789\n",
      "confusion matrix:\n",
      " [[378  14  59  37]\n",
      " [ 86 321  95 215]\n",
      " [ 14   3  78  12]\n",
      " [  3   4  23 283]]\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X, Y)\n",
    "\n",
    "print(\"5-fold CV error:\",CVError(qda,X,Y,cv=5))\n",
    "print(\"confusion matrix:\\n\",confusion_matrix(qda.predict(Xtest),Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare the performances of all above methods and give your comments.\n",
    "\n",
    "### Comparison of all above methods in table\n",
    "\n",
    "| Model         | Parameters to tune                  | CV Error            |\n",
    "| ------------- | ----------------------------------- | ------------------- |\n",
    "| Random Forest | num of trees, num of features       | 0.18717899877054156 |\n",
    "| Boosting Tree | num of trees, learning rates, depth | 0.18738370571995389 |\n",
    "| LDA           |                                     | 0.20058739755877364 |\n",
    "| QDA           |                                     | 0.3147670276728789  |\n",
    "\n",
    "### Comments\n",
    "\n",
    "The Random Forest and Boosting Tree models have better performance(based on CV Error metric), but there is not free launch since these two models require tuning parameter manually and massive computing time. LDA and QDA models run faster than previous two tree based model, but they also have limitation on the type of dataset. In this dataset, LDA performs better than QDA. However, in practice, we also have to try different methods and choose the best one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Spectral Clustering on 20newsgroup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis_clustering_error_rate(pred,real,nclass):\n",
    "    pred_list = list(pred)\n",
    "    errors = []\n",
    "    for perm in permutations(range(nclass)):\n",
    "        perm_pred = np.array([perm[x] for x in pred_list])\n",
    "        errors.append(1-accuracy_score(perm_pred,real))\n",
    "    return min(errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Apply PCA on the binary occurrence matrix and apply K-means clustering. \n",
    "Basically, take the top \n",
    "4 left singular vectors of the occurrence matrix (of size 16242x100) and apply K-means on the \n",
    "rows of these singular vectors with K=4. Report the mis-clustering error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mis-clustering_error_rate: 0.591092563453513\n"
     ]
    }
   ],
   "source": [
    "n4data = PCA(n_components=4).fit_transform(X)   \n",
    "km4 = KMeans(n_clusters=4,random_state=5054)\n",
    "km4.fit(n4data)\n",
    "print(\"mis-clustering_error_rate:\", mis_clustering_error_rate(km4.labels_,Y-1,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now take the top 5 left singular vectors of the occurrence matrix and apply K-means on the rows \n",
    "of these singular vectors with K=4. \n",
    "Report the mis-clustering error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mis-clustering_error_rate: 0.591092563453513\n"
     ]
    }
   ],
   "source": [
    "n5data = PCA(n_components=5).fit_transform(X)   \n",
    "km5 = KMeans(n_clusters=4,random_state=5054)\n",
    "km5.fit(n4data)\n",
    "print(\"mis-clustering_error_rate:\", mis_clustering_error_rate(km5.labels_,Y-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare with the performances from part I. \n",
    "\n",
    "The performance of this K-means based on PCA model is poorer than the model from part I, but it's easy to understand since these model in part II only use 4 or 5 principle components then the models can only use part of information from the dataset. However, on the other hand, this method is easier to perform and save computation time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
